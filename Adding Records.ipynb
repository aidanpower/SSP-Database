{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Adding new nodes\n",
        "Get SSP texts that are not in the network --> convert them to records --> if the intersect between their citations and the records in the network is great than the threshold, add them to the network.\n",
        "\n",
        "### <u>Running Order for the Cells</u>\n",
        "\n",
        "- Import the desired Pandas and Metaknowledge packages\n",
        "- Define the global variables for the Column Order of the Database, the Path of the file directories and the Database list of Record Citation Objects\n",
        "- Run the cell containing all of the functions\n",
        "- Run the following cells up until the matrix is created and then check the articles for SSP contents\n",
        "    - If an article does not reference the SSPs, remove it from the Database and mark it in red in the matrix file\n",
        "- Run the last cell to create the text records after having gone through the new entries in the database"
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import metaknowledge as mk"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# column_order is the order in which the columns appear in the SSP database\n",
        "column_order = [\"Continent\", \"Region\", \"SSPs\", \"RCPs\", \"Combinations\", \"Title\", \"Authors\", \"Year\", \"Abstract\", \"Primary Sector\", \"Secondary Sectors\", \"Type\", \"URL\", \"DOI\", \"WOS\"]\n",
        "\n",
        "# the path for the file directories, edit as required\n",
        "# the path will be different on different machines, this is currently for MAC OS\n",
        "path = '/Users/aidanpower/Desktop/OneDrive - University of Waterloo/Research/'\n",
        "\n",
        "# the record collection for existing files in the database\n",
        "DatabaseRC = mk.RecordCollection(path + \"SSP citations/\")\n",
        "Database = [R.createCitation() for R in DatabaseRC] "
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create_dict consumes a Record Collection and creates a dictiary of key and value pairs for each new entry in the database. \n",
        "# Each Key is a new Record Citation Object and each Value is a list of all of the Record Citation Objects from the Key's references.\n",
        "# The Web of Science ID strings are used to make comparisons between articles that are already in the database and those that are not. \n",
        "# Records that don't have any citations in the database are removed before the dictionary is returned. \n",
        "# create_dict: RecordCollection --> dictof()\n",
        "# Effects: Writes a .txt file to disk containing the WOSIDs\n",
        "\n",
        "def create_dict(RecordCollection):\n",
        "    dictionary = {}\n",
        "    WOS_list = []\n",
        "\n",
        "    previous_entries = list(df[\"WOS\"])\n",
        "    for Record in RecordCollection:\n",
        "        Citations = Record.get(\"CR\")\n",
        "        threshold = []\n",
        "        if not(Record.get(\"UT\") in previous_entries):\n",
        "            if type(Citations) != type(None):\n",
        "                for cite in Citations:\n",
        "                    if cite in Database:\n",
        "                        threshold.append(cite)\n",
        "                dictionary[Record.createCitation()] = threshold\n",
        "            if len(threshold) > 0:\n",
        "                WOS_list.append(Record.get(\"UT\"))\n",
        "  \n",
        "    # filter the dictionary\n",
        "    dictionary = {i:dictionary[i] for i in dictionary if len(dictionary[i])>0}\n",
        "    \n",
        "    # Write WOS_list to file\n",
        "    try:\n",
        "        file = open(path + \"WOS_list.txt\", 'w')\n",
        "        for WOSID in WOS_list:\n",
        "            file.write(\"{}\\n\".format(WOSID))\n",
        "        print(\"File successfully saved!\")\n",
        "        file.close()\n",
        "        return dictionary\n",
        "    except: \n",
        "        print(\"The file WOS_list.txt could not be saved\\n\")\n",
        "    \n",
        "\n",
        "# create_matrix consumes the desired name of the file, the existing dictionary and the exisintg database. Using the Record Citation Objects\n",
        "# from the existing Database as the column titles and the Record Citation Objects from the dictionary of new entries as the row titles to \n",
        "# determine what each new entry cites from the exisiting database, that intersect is given the value 1. All other boxes are given the value 0.\n",
        "# create_matrix: Str, Dictionary, listof(Str) --> PandasDataframe\n",
        "# Effects: Writes a .csv file to disk containing the SSP Matrix for the given year\n",
        "\n",
        "def create_matrix(Name, Dictionary, Database):\n",
        "    matrix = pd.DataFrame(0, index = range(len(Dictionary) + 1), columns = range(len(Database) + 1), dtype = int)\n",
        "    rows, columns = matrix.shape\n",
        "    \n",
        "    for col in range(columns):\n",
        "        if col == 0:\n",
        "            continue\n",
        "        else:\n",
        "            matrix.loc[0, col] = Database[col - 1]\n",
        "            \n",
        "    for row in range(rows):\n",
        "        if row == 0:\n",
        "            continue\n",
        "        else:\n",
        "            matrix.loc[row, 0] = list(Dictionary.keys())[row - 1]\n",
        "    rows, columns = matrix.shape\n",
        "    \n",
        "    for row in range(rows):\n",
        "        for col in range(columns):\n",
        "            if row == 0 or col == 0:\n",
        "                continue\n",
        "            else:\n",
        "                article = matrix.loc[0, col]\n",
        "                if article in list(Dictionary.values())[row - 1]:\n",
        "                    #print(\"{}, {}\".format(i,j))\n",
        "                    matrix.loc[row, col] = 1\n",
        "                    continue                     \n",
        "    try:               \n",
        "        matrix.to_csv(\"Matrices/\" + Name)\n",
        "        print(\"File successfully saved!\")\n",
        "        return matrix\n",
        "    except: \n",
        "        print(\"The CSV file for {} could not be saved\\n\".format(Name))    \n",
        " \n",
        "\n",
        "# new_entries creates a new dataframe by consuming the given RecordCollection and entering the new Records into the dataframe.\n",
        "# The information from the Records is as follows: Full name of Authors, Abstract, DOI, Publication Year, Data Type and the WOS ID number.\n",
        "# new_entries: RecordCollection --> PandasDataframe\n",
        "\n",
        "def new_entries(RecordCollection, Dictionary):\n",
        "    new_df = pd.DataFrame(columns = column_order)\n",
        "    n = 0\n",
        "    citation_objs = list(map(lambda x: str(x), Dictionary))\n",
        "    \n",
        "    for Record in RecordCollection:\n",
        "        if str(Record.createCitation()) in citation_objs:\n",
        "            entry = pd.DataFrame(columns = column_order)\n",
        "            labels = {\"Authors\":\"AF\", \"Title\":\"TI\", \"Abstract\":\"AB\", \"DOI\":\"DI\", \"Year\":\"PY\", \"Type\":\"DT\", \"WOS\":\"UT\"}\n",
        "            \n",
        "            for label in labels:\n",
        "                try:\n",
        "                    if label == \"Authors\":\n",
        "                        authors = Record.get(labels[label])\n",
        "                        b = \"\"\n",
        "                        for i in range(len(authors)): \n",
        "                            b = b + authors[i]+ \"; \"\n",
        "                        b = b.strip()\n",
        "                        entry[\"Authors\"] = [b[:-2]]\n",
        "                    elif label == \"DOI\":\n",
        "                        doi = Record.get(labels[label]).lower()\n",
        "                        entry[\"DOI\"] = doi\n",
        "                    else:\n",
        "                        entry[label] = Record.get(labels[label])\n",
        "                except: \n",
        "                    print(\"The {} for '{}' could not be found\\n\".format(label, Record.createCitation()))\n",
        "            new_df = pd.concat([entry, new_df], ignore_index = True)\n",
        "    return new_df\n",
        "    \n",
        "\n",
        "# writefile consumes the desired name of the file and saves the database as an Excel file. It takes the existing database and \n",
        "# adds the new entries to it before saving it as an Excel file.  \n",
        "# writefile: Str --> None\n",
        "# Effects: Writes a .xlxs file to disk containing the SSP Database\n",
        "\n",
        "def writefile(Name, Dictionary):\n",
        "    try:\n",
        "        writer = pd.ExcelWriter(path + Name, engine=\"xlsxwriter\")\n",
        "\n",
        "        newdf = pd.concat([df, new_entries(newRC, Dictionary)], ignore_index=True)\n",
        "        newdf = newdf[column_order]\n",
        "        newdf.to_excel(writer, sheet_name= \"DB 3.0\", na_rep=\"\", freeze_panes=(1,0), index=False)\n",
        "\n",
        "        workbook = writer.book\n",
        "        worksheet = writer.sheets[\"DB 3.0\"]\n",
        "\n",
        "        header_format = workbook.add_format({'bold':True, 'fg_color':'#FABF8F', 'border':0, 'font_size':11})\n",
        "        for col_num, value in enumerate(newdf.columns.values):\n",
        "            worksheet.write(0, col_num, value, header_format)\n",
        "\n",
        "        writer.save()\n",
        "        print(\"File successfully saved!\")\n",
        "        writer.close()        \n",
        "    except: \n",
        "        print(\"The Excel file for {} could not be saved\\n\".format(Name))\n",
        "    \n",
        "    \n",
        "# add_records adds a new record file to the existing folder of record collections (path/SSP Citations/) that contains all of the\n",
        "# plain text records for the most recent record collection add to the database, after it has been screened for articles that were\n",
        "# incorrectly included in the excel file database. This encorporates the list of Web of Science IDs that was saved previously.\n",
        "# add_records: Str --> None\n",
        "# Effects: Writes a .txt file to disk containing the \n",
        "\n",
        "def add_records(Name):\n",
        "    NewRC = mk.RecordCollection()    \n",
        "    previous_entries = list(df[\"WOS\"])\n",
        "    \n",
        "    file = open(\"WOS_list.txt\", 'r')\n",
        "    lines = file.readlines()\n",
        "    WOS_list = list(map(lambda WOSID: WOSID.strip(), lines))\n",
        "    \n",
        "    for WOSID in WOS_list:\n",
        "        if not(WOSID in previous_entries):\n",
        "            try: \n",
        "                Record = newRC.getID(WOSID)\n",
        "                NewRC.add(Record)\n",
        "            except:\n",
        "                print(\"The record for {} could not be found\\n\".format(WOSID))\n",
        "    try:\n",
        "        NewRC.writeFile(path + Name)\n",
        "        print(\"File successfully saved!\")\n",
        "    except: \n",
        "        print(\"The RecordCollection file for {} could not be saved\\n\".format(Name))"
      ],
      "outputs": [],
      "execution_count": 57,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Updating the excel database\n",
        "\n",
        "# DO NOT RUN ME\n",
        "\n",
        "if 1 == 0:\n",
        "    path = '/Users/aidanpower/Desktop/OneDrive - University of Waterloo/Research/'\n",
        "\n",
        "    df = pd.read_excel(path + \"Database.xlsx\", sheetname = \"DB 3.0\")\n",
        "    \"\"\"\n",
        "    WOS_dict = {}\n",
        "    AU = {}\n",
        "    l = list(df[\"DOI\"])\n",
        "    for i in l:\n",
        "        i = str(i).lower()\n",
        "    for R in DatabaseRC:\n",
        "        doi = R.get(\"DI\").lower()\n",
        "        if doi in l:\n",
        "            AU[doi] = R.get(\"AF\")\n",
        "            WOS_dict[doi] = R.get(\"UT\")\n",
        "\n",
        "    for i in AU:\n",
        "        b = \"\"\n",
        "        for a in AU[i]:\n",
        "            b = b + a + \"; \"\n",
        "            AU[i] = b\n",
        "        AU[i] = AU[i][:-2]\n",
        "    \n",
        "    \n",
        "    for w in WOS_dict:\n",
        "        row = df.loc[df[\"DOI\"] == w].index\n",
        "        df[\"WOS\"][row] = WOS_dict[w]\n",
        "        df[\"Authors\"][row] = AU[w]\n",
        "    \"\"\"\n",
        "    "
      ],
      "outputs": [],
      "execution_count": 58,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# newRC is the record collection for files to be added\n",
        "newRC = mk.RecordCollection(path + \"Testing info/SSP 2018.txt\")\n",
        "\n",
        "# Create a pandas dataframe from the Database excel file, from before new entries are added\n",
        "df = pd.read_excel(path + \"Database.xlsx\", sheetname = \"DB 3.0\")\n",
        "\nDictionary = create_dict(newRC)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File successfully saved!\n"
          ]
        }
      ],
      "execution_count": 59,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "writefile(\"Database.xlsx\", Dictionary)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File successfully saved!\n"
          ]
        }
      ],
      "execution_count": 60,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = create_matrix(\"SSP citation matrix.csv\", Dictionary, Database)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File successfully saved!\n"
          ]
        }
      ],
      "execution_count": 61,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STOP here and check the entires\n",
        "\nHere is where you want to look through the new entries in the excel database. If an entry does not make use of the SSPs, delete it from the database by removing the row and mark the entry in red in the matrix citation file. Once that is done, you can add the records."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pandas dataframe from the Database excel file, from after new entries are added\n",
        "df = pd.read_excel(path + \"Database.xlsx\", sheetname = \"DB 3.0\")\n",
        "\nadd_records(\"SSP Citations/SSP 2018.txt\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "count, any that are over one compare with the 107 features of the matrix database and see what papers specifically are being cited. Create a new record collection, each fo the objects is one of the records that have at least one citation. Retrieve the new record collection and feed it to the matirx \n",
        "\nCurrent search string: TS = (Shared AND (Socioeconomic OR Socio-economic) AND Pathway*) AND PY = (2011-2018)) AND LANGUAGE: (English)"
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}